{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "127e347d-a748-40d1-99ac-7ac5178e9033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 19:54:46.003881: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import SAC, TD3, A2C\n",
    "import os\n",
    "import argparse\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41e28239-2918-47fe-91f9-7b9d11f46ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create base directories\n",
    "model_base_dir = \"models\"\n",
    "log_base_dir = \"logs\"\n",
    "os.makedirs(model_base_dir, exist_ok=True)\n",
    "os.makedirs(log_base_dir, exist_ok=True)\n",
    "\n",
    "name = \"SAC_\"\n",
    "\n",
    "# Find next available index\n",
    "existing_dirs = [d for d in os.listdir(log_base_dir) if d.startswith(name) and d[4:].isdigit()]\n",
    "next_index = max([int(d[4:]) for d in existing_dirs], default=-1) + 1\n",
    "\n",
    "# Create log and model directories with same name\n",
    "log_dir = os.path.join(log_base_dir, f\"{name}{next_index}\")\n",
    "model_dir = os.path.join(model_base_dir, f\"{name}{next_index}\")\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "def train(model, timesteps):\n",
    "    iters = 0\n",
    "    while True:\n",
    "        iters += 1\n",
    "        model.learn(total_timesteps=timesteps, reset_num_timesteps=False)\n",
    "        # Save to models/SAC_X/\n",
    "        model.save(f\"{model_dir}/model_{model.num_timesteps}\")\n",
    "    return model\n",
    "# def train(model, timesteps, ):\n",
    "\n",
    "    \n",
    "\n",
    "#     iters = 0\n",
    "#     while True:\n",
    "#         iters += 1\n",
    "#         model.learn(total_timesteps=timesteps, reset_num_timesteps=False)\n",
    "#         model.save(f\"{model_dir}{name}{next_index}{model.num_timesteps - model.num_timesteps % 1000}\")\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d4181f8-e82e-4e77-92f7-8ce3c96e9134",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"Humanoid-v5\", render_mode=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d709f098-8881-45c4-bdaa-efaaa5940b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "action_noise = NormalActionNoise(mean=np.zeros(env.action_space.shape), \n",
    "                                 sigma=0.15 * np.ones(env.action_space.shape))\n",
    "# model = SAC('MlpPolicy', env, verbose=1, device='cuda', tensorboard_log=log_dir)\n",
    "model = SAC(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    device=\"cuda\",\n",
    "    tensorboard_log=log_dir,\n",
    "    learning_rate=0.0004,        # Default, but can be reduced for more exploration\n",
    "    batch_size=512,              # Increase batch size for stability\n",
    "    tau=0.004,                   # Lower tau to slow down target updates\n",
    "    gamma=0.98,                  # Slightly reduce gamma to value short-term rewards more\n",
    "    ent_coef=0.06,               # Encourage more entropy (more randomness)\n",
    "    target_update_interval=2,     # Update targets slightly less frequently\n",
    "    action_noise=action_noise,     # Inject additional exploration noise\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5dde7eb-b817-49af-984a-0ba6ede794c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = SAC.load(\"models/SAC_736000\", verbose=1, device='cuda', tensorboard_log=log_dir)\n",
    "# model.set_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f7d1187-303b-4a4e-8c2a-5d53f1bc3bc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to logs/SAC_3/SAC_0\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.5     |\n",
      "|    ep_rew_mean     | 123      |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 106      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.14    |\n",
      "|    critic_loss     | 13.3     |\n",
      "|    ent_coef        | 0.06     |\n",
      "|    learning_rate   | 0.0004   |\n",
      "|    n_updates       | 5        |\n",
      "---------------------------------\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.6     |\n",
      "|    ep_rew_mean     | 105      |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 181      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.05    |\n",
      "|    critic_loss     | 0.768    |\n",
      "|    ent_coef        | 0.06     |\n",
      "|    learning_rate   | 0.0004   |\n",
      "|    n_updates       | 80       |\n",
      "---------------------------------\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.4     |\n",
      "|    ep_rew_mean     | 98.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 47       |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 257      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.27    |\n",
      "|    critic_loss     | 1.61     |\n",
      "|    ent_coef        | 0.06     |\n",
      "|    learning_rate   | 0.0004   |\n",
      "|    n_updates       | 156      |\n",
      "---------------------------------\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.1     |\n",
      "|    ep_rew_mean     | 91.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 322      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.33    |\n",
      "|    critic_loss     | 2.03     |\n",
      "|    ent_coef        | 0.06     |\n",
      "|    learning_rate   | 0.0004   |\n",
      "|    n_updates       | 221      |\n",
      "---------------------------------\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.4     |\n",
      "|    ep_rew_mean     | 87.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 387      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.08    |\n",
      "|    critic_loss     | 1.45     |\n",
      "|    ent_coef        | 0.06     |\n",
      "|    learning_rate   | 0.0004   |\n",
      "|    n_updates       | 286      |\n",
      "---------------------------------\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 18.8     |\n",
      "|    ep_rew_mean     | 84.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 158      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 451      |\n",
      "---------------------------------\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 18.4     |\n",
      "|    ep_rew_mean     | 82.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 514      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.1    |\n",
      "|    critic_loss     | 2.66     |\n",
      "|    ent_coef        | 0.06     |\n",
      "|    learning_rate   | 0.0004   |\n",
      "|    n_updates       | 413      |\n",
      "---------------------------------\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 18       |\n",
      "|    ep_rew_mean     | 80.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 576      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.2    |\n",
      "|    critic_loss     | 0.877    |\n",
      "|    ent_coef        | 0.06     |\n",
      "|    learning_rate   | 0.0004   |\n",
      "|    n_updates       | 475      |\n",
      "---------------------------------\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 17.8     |\n",
      "|    ep_rew_mean     | 79.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 38       |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 639      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.8    |\n",
      "|    critic_loss     | 0.534    |\n",
      "|    ent_coef        | 0.06     |\n",
      "|    learning_rate   | 0.0004   |\n",
      "|    n_updates       | 538      |\n",
      "---------------------------------\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 17.6     |\n",
      "|    ep_rew_mean     | 78.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 68       |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 702      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.2    |\n",
      "|    critic_loss     | 0.543    |\n",
      "|    ent_coef        | 0.06     |\n",
      "|    learning_rate   | 0.0004   |\n",
      "|    n_updates       | 601      |\n",
      "---------------------------------\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 17.4     |\n",
      "|    ep_rew_mean     | 78.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 766      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.7    |\n",
      "|    critic_loss     | 0.51     |\n",
      "|    ent_coef        | 0.06     |\n",
      "|    learning_rate   | 0.0004   |\n",
      "|    n_updates       | 665      |\n",
      "---------------------------------\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 17.3     |\n",
      "|    ep_rew_mean     | 77.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 830      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.3    |\n",
      "|    critic_loss     | 0.407    |\n",
      "|    ent_coef        | 0.06     |\n",
      "|    learning_rate   | 0.0004   |\n",
      "|    n_updates       | 729      |\n",
      "---------------------------------\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 17.2     |\n",
      "|    ep_rew_mean     | 76.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 892      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.1    |\n",
      "|    critic_loss     | 0.386    |\n",
      "|    ent_coef        | 0.06     |\n",
      "|    learning_rate   | 0.0004   |\n",
      "|    n_updates       | 791      |\n",
      "---------------------------------\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 17       |\n",
      "|    ep_rew_mean     | 76.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 52       |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 954      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.7    |\n",
      "|    critic_loss     | 0.472    |\n",
      "|    ent_coef        | 0.06     |\n",
      "|    learning_rate   | 0.0004   |\n",
      "|    n_updates       | 853      |\n",
      "---------------------------------\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 16.9     |\n",
      "|    ep_rew_mean     | 76       |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 1017     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.9    |\n",
      "|    critic_loss     | 0.491    |\n",
      "|    ent_coef        | 0.06     |\n",
      "|    learning_rate   | 0.0004   |\n",
      "|    n_updates       | 916      |\n",
      "---------------------------------\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 16.9     |\n",
      "|    ep_rew_mean     | 76       |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 1083     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -19      |\n",
      "|    critic_loss     | 1.11     |\n",
      "|    ent_coef        | 0.06     |\n",
      "|    learning_rate   | 0.0004   |\n",
      "|    n_updates       | 982      |\n",
      "---------------------------------\n",
      "Logging to logs/SAC_3/SAC_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 16.9     |\n",
      "|    ep_rew_mean     | 76       |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 1150     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -19.1    |\n",
      "|    critic_loss     | 0.325    |\n",
      "|    ent_coef        | 0.06     |\n",
      "|    learning_rate   | 0.0004   |\n",
      "|    n_updates       | 1049     |\n",
      "---------------------------------\n",
      "Logging to logs/SAC_3/SAC_0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, timesteps)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     iters \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Save to models/SAC_X/\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mnum_timesteps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/stable_baselines3/sac/sac.py:307\u001b[0m, in \u001b[0;36mSAC.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfSAC,\n\u001b[1;32m    300\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    306\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfSAC:\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py:347\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;66;03m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m gradient_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 347\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/stable_baselines3/sac/sac.py:215\u001b[0m, in \u001b[0;36mSAC.train\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    211\u001b[0m actor_losses, critic_losses \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gradient_step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(gradient_steps):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# Sample replay buffer\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m     replay_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vec_normalize_env\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# We need to sample because `log_std` may have changed between two gradient steps\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_sde:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/stable_baselines3/common/buffers.py:298\u001b[0m, in \u001b[0;36mReplayBuffer.sample\u001b[0;34m(self, batch_size, env)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03mSample elements from the replay buffer.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03mCustom sampling when using memory efficient variant,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimize_memory_usage:\n\u001b[0;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Do not sample the element with index `self.pos` as the transitions is invalid\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# (we use only one array to store `obs` and `next_obs`)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfull:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/stable_baselines3/common/buffers.py:115\u001b[0m, in \u001b[0;36mBaseBuffer.sample\u001b[0;34m(self, batch_size, env)\u001b[0m\n\u001b[1;32m    113\u001b[0m upper_bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_size \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfull \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos\n\u001b[1;32m    114\u001b[0m batch_inds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, upper_bound, size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_inds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/stable_baselines3/common/buffers.py:325\u001b[0m, in \u001b[0;36mReplayBuffer._get_samples\u001b[0;34m(self, batch_inds, env)\u001b[0m\n\u001b[1;32m    314\u001b[0m     next_obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_obs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_observations[batch_inds, env_indices, :], env)\n\u001b[1;32m    316\u001b[0m data \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_obs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservations[batch_inds, env_indices, :], env),\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactions[batch_inds, env_indices, :],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_reward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards[batch_inds, env_indices]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), env),\n\u001b[1;32m    324\u001b[0m )\n\u001b[0;32m--> 325\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ReplayBufferSamples(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_torch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/stable_baselines3/common/buffers.py:139\u001b[0m, in \u001b[0;36mBaseBuffer.to_torch\u001b[0;34m(self, array, copy)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03mConvert a numpy array to a PyTorch tensor.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03mNote: it copies the data by default\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m th\u001b[38;5;241m.\u001b[39mas_tensor(array, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train(model, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e8145bf-59d7-49cb-bd04-5e3cdf9783b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/SAC_1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(\"models/SAC_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef8fc4d-3296-4b44-aed7-8952d7671ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
